# ESPN Data Pipeline

An end-to-end **ELT data pipeline** that ingests live ESPN API data, loads it into **Snowflake**, transforms it with **dbt**, and orchestrates everything using **Apache Airflow**.

> Built as a demonstration of modern data engineering practices: containerized orchestration, cloud warehouse modeling, and reproducible transformations.

---

## ğŸš€ Features
- **Automated ingestion** from ESPN API (Python requests â†’ JSON).
- **Snowflake landing zone** for raw VARIANT data.
- **dbt models** to transform and normalize JSON into fact/dimension tables.
- **Airflow DAG** for orchestration (extract â†’ load â†’ transform â†’ test).
- **Deduplication** strategy to handle repeated API payloads.
- **Dockerized environment** for reproducibility.

---

## ğŸ“‚ Repository Structure


---

## ğŸ— Architecture

         +-------------+
         |  ESPN API   | 
         +------+------+ 
                |
                v
         +------+------------------+
         |   Python Extract/Load   |   â† Request data from ESPN's public API
         +-------+-----------------+
                 |
                 v
         +-------+------------+
         | Snowflake (RAW)    |   â† Insert raw json objects into Snowflake database
         +----------+---------+
                    |
                    v
         +----------+--------------------+
         | dbt (Staging/Transformation)  |   â† Apply dbt transformations to create various tables inside Snowflake
         +-----------+-------------------+
                     |
                     v
         +-----------+----------+
         | Airflow Orchestration|   â† Automate the entire pipeline to run daily
         +----------------------+
